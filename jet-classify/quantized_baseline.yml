model:
  name: quantized
  l1: 0.0001
  shape:
    - 64
    - 32
    - 32
  quantization:
    fc_bits: 6
    fc_int_bits: 0
    relu_bits: 6
    input_bits: 16
    input_int_bits: 5
fit:
  batch_size: 1024
  compile:
    loss: categorical_crossentropy
    optimizer: adam
  epochs: 100
  shuffle: True
  validation_split: 0.25
  verbose: True
model_directory: ./model/quantized_baseline